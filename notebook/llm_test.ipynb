{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# UniversalLLM 基本功能测试\n\n测试简化后的UniversalLLM类的基本功能"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 导入必要的库\nimport sys\nfrom pathlib import Path\n\n# 添加项目路径\nsys.path.append(str(Path.cwd().parent))\n\nfrom llm_api.universal_llm import create_llm"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. 创建LLM实例并查看配置状态"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 创建LLM实例\nllm = create_llm()\n\n# 查看配置状态\nprint(\"=== LLM配置状态 ===\")\nstatus = llm.get_status()\nfor key, value in status.items():\n    print(f\"{key}: {value}\")\n\nprint(f\"\\n当前激活的fallback列表: {status['active_fallback_list']}\")\nprint(f\"可用的providers: {status['available_providers']}\")\nprint(f\"已初始化的clients: {status['initialized_clients']}\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 2. 基本文本生成测试"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# 简单的文本生成测试\nprint(\"=== 基本文本生成测试 ===\")\n\ntest_prompt = \"简单回答：1+1等于几？\"\n\ntry:\n    response = llm.generate(test_prompt, verbose=True)\n    print(f\"\\n✅ 测试成功！\")\n    print(f\"回复: {response}\")\n    print(f\"使用的provider: {llm.current_provider}\")\nexcept Exception as e:\n    print(f\"❌ 测试失败: {e}\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 3. 中文问答测试"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 中文问答测试\nprint(\"=== 中文问答测试 ===\")\n\nchinese_prompt = \"用中文简单介绍一下Python编程语言的特点（50字以内）\"\n\ntry:\n    response = llm.generate(chinese_prompt)\n    print(f\"✅ 中文回复成功\")\n    print(f\"问题: {chinese_prompt}\")\n    print(f\"回复: {response}\")\n    print(f\"使用provider: {llm.current_provider}\")\nexcept Exception as e:\n    print(f\"❌ 中文回复失败: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Fallback机制测试\n\n测试当第一个provider不可用时，是否能自动切换到下一个provider"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 测试fallback机制\nprint(\"=== Fallback机制测试 ===\")\n\n# 显示当前fallback顺序\nprint(f\"当前fallback顺序: {llm.config.get('active_fallback_list', [])}\")\n\n# 进行几次调用，观察是否稳定使用相同provider\nfor i in range(3):\n    try:\n        response = llm.generate(f\"回答数字：{i+1}\")\n        print(f\"第{i+1}次调用成功，使用provider: {llm.current_provider}\")\n    except Exception as e:\n        print(f\"第{i+1}次调用失败: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. 总结\n\n简化后的UniversalLLM主要特性：\n\n1. **配置简单**: 所有配置都在 `configs/base.yaml` 中\n2. **自动fallback**: 按照 `active_fallback_list` 顺序尝试不同provider\n3. **支持多种API**: OpenAI兼容API (gpt_free, gpt_light, gpt_pro) 和 Ollama本地API\n4. **代码简洁**: 去掉了复杂的配置验证和环境变量fallback逻辑\n\n使用方法：\n```python\nfrom llm_api.universal_llm import create_llm\n\nllm = create_llm()\nresponse = llm.generate(\"你的问题\")\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 简单的性能测试\n",
    "def performance_test(llm, name, prompt=\"简单回答：1+1等于几？\"):\n",
    "    print(f\"\\n{name} 性能测试:\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        response = llm.generate(prompt, verbose=False)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"耗时: {end_time - start_time:.2f}秒\")\n",
    "        print(f\"回复: {response}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        end_time = time.time()\n",
    "        print(f\"失败 (耗时: {end_time - start_time:.2f}秒): {e}\")\n",
    "        return False\n",
    "\n",
    "# 测试可用的LLM\n",
    "performance_test(ollama_llm, \"Ollama\")\n",
    "\n",
    "if openai_llm:\n",
    "    performance_test(openai_llm, \"OpenAI\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}