{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UniversalLLM 基本功能测试\n",
    "\n",
    "测试简化后的UniversalLLM类的基本功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
<<<<<<< HEAD
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 添加项目路径\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from llm_api.universal_llm import create_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 创建LLM实例并查看配置状态"
=======
    "import asyncio\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "# 导入项目包和配置\n",
    "from llm_api.universal_llm import create_llm\n",
    "from utils.config_utils import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 创建LLM实例并查看配置状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 可用配置测试 ===\n",
      "\n",
      "--- 配置: base ---\n",
      "Market: Binance\n",
      "Window: 365\n",
      "Fee: 0.0003\n",
      "Active fallback: ['gpt_light', 'gpt_free', 'ollama']\n",
      "Available providers: ['gpt_light', 'gpt_free', 'gpt_pro', 'ollama']\n",
      "  gpt_light: gemini_flash - gemini-2.5-flash (max_concurrent: 10)\n",
      "  gpt_free: openroute - deepseek/deepseek-chat-v3-0324:free (max_concurrent: 5)\n",
      "  gpt_pro: gemini - gemini-2.5-pro-preview-06-05 (max_concurrent: 8)\n",
      "  ollama: ollama - qwen3:4b (max_concurrent: 1)\n",
      "\n",
      "--- 配置: ollama ---\n",
      "Market: Binance\n",
      "Window: 365\n",
      "Fee: 0.0003\n",
      "Active fallback: ['ollama']\n",
      "Available providers: ['ollama']\n",
      "  ollama: ollama - qwen3:4b (max_concurrent: 2)\n",
      "\n",
      "=== 选择配置创建LLM实例 ===\n",
      "使用配置: base\n",
      "已重置LLM单例\n",
      "=== LLM配置状态 ===\n",
      "active_fallback_list: ['gpt_light', 'gpt_free', 'ollama']\n",
      "current_provider: None\n",
      "current_provider_type: None\n",
      "current_model: None\n",
      "max_retries: 3\n",
      "temperature: 0.7\n",
      "timeout_config: {'connection': 10, 'read': 30, 'total': 120}\n",
      "available_providers: ['gpt_light', 'gpt_free', 'gpt_pro', 'ollama']\n",
      "initialized_clients: ['gpt_light', 'gpt_free', 'gpt_pro']\n",
      "\n",
      "当前激活的fallback列表: ['gpt_light', 'gpt_free', 'ollama']\n",
      "可用的providers: ['gpt_light', 'gpt_free', 'gpt_pro', 'ollama']\n",
      "已初始化的clients: ['gpt_light', 'gpt_free', 'gpt_pro']\n"
     ]
    }
   ],
   "source": [
    "# 使用Config配置系统创建LLM实例\n",
    "print(\"=== 可用配置测试 ===\")\n",
    "\n",
    "# 测试不同配置\n",
    "configs = ['base', 'ollama']\n",
    "for config_name in configs:\n",
    "    print(f\"\\n--- 配置: {config_name} ---\")\n",
    "    config = Config(config_name)\n",
    "    settings = config.settings  # 获取配置实例\n",
    "    \n",
    "    # 显示基本配置摘要\n",
    "    print(f\"Market: {settings.market.universe}\")\n",
    "    print(f\"Window: {settings.market.window}\")  \n",
    "    print(f\"Fee: {settings.market.fee}\")\n",
    "    \n",
    "    # 显示LLM配置\n",
    "    if settings.llm:\n",
    "        print(f\"Active fallback: {settings.llm.get('active_fallback_list', [])}\")\n",
    "        providers = settings.llm.get('providers', {})\n",
    "        print(f\"Available providers: {list(providers.keys())}\")\n",
    "        \n",
    "        # 显示provider详情\n",
    "        for name, provider_config in providers.items():\n",
    "            print(f\"  {name}: {provider_config.get('provider')} - {provider_config.get('model')} (max_concurrent: {provider_config.get('max_concurrent', 1)})\")\n",
    "\n",
    "print(\"\\n=== 选择配置创建LLM实例 ===\")\n",
    "# 使用base配置，确保有可用的API providers\n",
    "CONFIG_NAME = \"base\"  \n",
    "\n",
    "print(f\"使用配置: {CONFIG_NAME}\")\n",
    "\n",
    "# 重置单例（仅在需要切换配置时使用）\n",
    "from llm_api.universal_llm import UniversalLLM\n",
    "UniversalLLM.reset_instance()\n",
    "print(\"已重置LLM单例\")\n",
    "\n",
    "# 直接使用配置名称创建LLM实例\n",
    "llm = create_llm(CONFIG_NAME)\n",
    "\n",
    "# 查看配置状态\n",
    "print(\"=== LLM配置状态 ===\")\n",
    "status = llm.get_status()\n",
    "for key, value in status.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\n当前激活的fallback列表: {status['active_fallback_list']}\")\n",
    "print(f\"可用的providers: {status['available_providers']}\")\n",
    "print(f\"已初始化的clients: {status['initialized_clients']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 基本文本生成测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 基本文本生成测试 ===\n",
      "Using gpt_light (attempt 1/3)...\n",
      "✅ gpt_light succeeded\n",
      "\n",
      "✅ 测试成功！\n",
      "回复: 2\n",
      "使用的provider: gpt_light\n"
     ]
    }
   ],
   "source": [
    "# 简单的文本生成测试\n",
    "print(\"=== 基本文本生成测试 ===\")\n",
    "\n",
    "test_prompt = \"简单回答：1+1等于几？\"\n",
    "\n",
    "try:\n",
    "    response = llm.generate(test_prompt, verbose=True)\n",
    "    print(f\"\\n✅ 测试成功！\")\n",
    "    print(f\"回复: {response}\")\n",
    "    print(f\"使用的provider: {llm.current_provider}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 测试失败: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 中文问答测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 中文问答测试 ===\n",
      "✅ 中文回复成功\n",
      "问题: 用中文简单介绍一下Python编程语言的特点（50字以内）\n",
      "回复: Python是一种**易学、可读性强**的**高级编程语言**，以其**简洁**的语法和**丰富**的库支持，**功能强大**且**用途广泛**。\n",
      "使用provider: gpt_light\n"
     ]
    }
   ],
   "source": [
    "# 中文问答测试\n",
    "print(\"=== 中文问答测试 ===\")\n",
    "\n",
    "chinese_prompt = \"用中文简单介绍一下Python编程语言的特点（50字以内）\"\n",
    "\n",
    "try:\n",
    "    response = llm.generate(chinese_prompt)\n",
    "    print(f\"✅ 中文回复成功\")\n",
    "    print(f\"问题: {chinese_prompt}\")\n",
    "    print(f\"回复: {response}\")\n",
    "    print(f\"使用provider: {llm.current_provider}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 中文回复失败: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fallback机制测试\n",
    "\n",
    "测试当第一个provider不可用时，是否能自动切换到下一个provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fallback机制测试 ===\n",
      "当前fallback顺序: ['gpt_light', 'gpt_free', 'ollama']\n",
      "第1次调用成功，使用provider: gpt_light,1\n",
      "第2次调用成功，使用provider: gpt_light,2\n",
      "第3次调用成功，使用provider: gpt_light,3\n"
     ]
    }
   ],
   "source": [
    "# 测试fallback机制\n",
    "print(\"=== Fallback机制测试 ===\")\n",
    "\n",
    "# 显示当前fallback顺序\n",
    "print(f\"当前fallback顺序: {llm.config.get('active_fallback_list', [])}\")\n",
    "\n",
    "# 进行几次调用，观察是否稳定使用相同provider\n",
    "for i in range(3):\n",
    "    try:\n",
    "        response = llm.generate(f\"回答数字：{i+1}\")\n",
    "        print(f\"第{i+1}次调用成功，使用provider: {llm.current_provider},{response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"第{i+1}次调用失败: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 在脚本中使用：\n",
    "```python\n",
    "from llm_api.universal_llm import create_llm\n",
    "\n",
    "# 使用指定配置创建LLM实例（单例模式，第一次调用决定配置）\n",
    "llm = create_llm(\"ollama\")  # 或 \"base\" 或 None (默认)\n",
    "response = llm.generate(\"你的问题\")\n",
    "```\n",
    "\n",
    "### 2. 命令行测试：\n",
    "```bash\n",
    "# 在项目根目录运行\n",
    "python test/test_config.py show --config_name ollama\n",
    "python test/test_config.py show --config_name base\n",
    "python test/test_config.py test\n",
    "```\n",
    "\n",
    "### 3. 在Notebook中切换配置：\n",
    "```python\n",
    "# 修改CONFIG_NAME变量并重新运行cell-3即可切换配置\n",
    "CONFIG_NAME = \"ollama\"  # 或 \"base\"\n",
    "\n",
    "# 单例模式说明：\n",
    "# - 第一次创建LLM实例时，配置会被锁定\n",
    "# - 后续尝试使用不同配置会被忽略并警告\n",
    "# - 如需切换配置，需要先reset_instance()（仅开发测试时使用）\n",
    "```\n",
    "\n",
    "### 4. 直接使用Config类查看配置：\n",
    "```python\n",
    "from utils.config_utils import Config\n",
    "\n",
    "# 查看配置详情\n",
    "config = Config(\"ollama\")\n",
    "settings = config.settings\n",
    "print(f\"Market universe: {settings.market.universe}\")\n",
    "print(f\"LLM providers: {list(settings.llm['providers'].keys())}\")\n",
    "```\n",
    "\n",
    "### 配置说明：\n",
    "- **ollama**: 纯本地模型（需要先启动ollama服务）\n",
    "- **base**: 多个API provider with fallback（需要.env中的API keys）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 更新的性能测试 ===\n",
      "当前使用的fallback列表: ['gpt_light', 'gpt_free', 'ollama']\n",
      "可用providers: ['gpt_light', 'gpt_free', 'gpt_pro', 'ollama']\n",
      "\n",
      "数学问题 性能测试:\n",
      "✅ 耗时: 3.29秒\n",
      "使用provider: gpt_light\n",
      "回复: 2\n",
      "\n",
      "中文问答 性能测试:\n",
      "✅ 耗时: 9.80秒\n",
      "使用provider: gpt_light\n",
      "回复: Python是一种语法简洁、易于学习且功能强大的高级通用编程语言。\n",
      "\n",
      "英文问答 性能测试:\n",
      "✅ 耗时: 4.81秒\n",
      "使用provider: gpt_light\n",
      "回复: Machine learning is a subset of artificial intelligence that enables systems to learn from data, identify patterns, and make predictions without being explicitly programmed.\n",
      "\n",
      "总体测试结果: 3/3 成功\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 更新的性能测试\n",
    "def performance_test_updated():\n",
    "    \"\"\"更新的性能测试，使用新的create_llm接口\"\"\"\n",
    "    print(\"=== 更新的性能测试 ===\")\n",
    "    \n",
    "    # 创建LLM实例\n",
    "    llm = create_llm()\n",
    "    \n",
    "    # 显示配置状态\n",
    "    print(f\"当前使用的fallback列表: {llm.config.get('active_fallback_list', [])}\")\n",
    "    print(f\"可用providers: {list(llm.config.get('providers', {}).keys())}\")\n",
    "    \n",
    "    def single_performance_test(name, prompt=\"简单回答：1+1等于几？\"):\n",
    "        print(f\"\\n{name} 性能测试:\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            response = llm.generate(prompt, verbose=False)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            print(f\"✅ 耗时: {end_time - start_time:.2f}秒\")\n",
    "            print(f\"使用provider: {llm.current_provider}\")\n",
    "            print(f\"回复: {response}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            end_time = time.time()\n",
    "            print(f\"❌ 失败 (耗时: {end_time - start_time:.2f}秒): {e}\")\n",
    "            return False\n",
    "\n",
    "    # 测试不同类型的问题\n",
    "    test_cases = [\n",
    "        (\"数学问题\", \"简单回答：1+1等于几？\"),\n",
    "        (\"中文问答\", \"用一句话介绍Python\"),\n",
    "        (\"英文问答\", \"What is machine learning in one sentence?\")\n",
    "    ]\n",
    "    \n",
    "    success_count = 0\n",
    "    for name, prompt in test_cases:\n",
    "        if single_performance_test(name, prompt):\n",
    "            success_count += 1\n",
    "    \n",
    "    print(f\"\\n总体测试结果: {success_count}/{len(test_cases)} 成功\")\n",
    "    return success_count == len(test_cases)\n",
    "\n",
    "# 运行更新的性能测试\n",
    "performance_success = performance_test_updated()"
>>>>>>> 7f5a145781e4be1df374c9d1fdb11b39af106008
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": null,
>>>>>>> 7f5a145781e4be1df374c9d1fdb11b39af106008
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "=== LLM配置状态 ===\n",
      "active_fallback_list: ['gpt_free', 'ollama']\n",
      "current_provider: None\n",
      "current_provider_type: None\n",
      "current_model: None\n",
      "enable_streaming: False\n",
      "max_retries: 3\n",
      "temperature: 0.7\n",
      "available_providers: ['gpt_light', 'gpt_free', 'gpt_pro', 'ollama']\n",
      "initialized_clients: ['gpt_light', 'gpt_free', 'gpt_pro']\n",
      "\n",
      "当前激活的fallback列表: ['gpt_free', 'ollama']\n",
      "可用的providers: ['gpt_light', 'gpt_free', 'gpt_pro', 'ollama']\n",
      "已初始化的clients: ['gpt_light', 'gpt_free', 'gpt_pro']\n"
=======
      "=== 当前LLM状态 ===\n",
      "可用providers: ['gpt_light', 'gpt_free', 'gpt_pro', 'ollama']\n",
      "已初始化clients: ['gpt_light', 'gpt_free', 'gpt_pro']\n",
      "超时配置: {'connection': 10, 'read': 30, 'total': 120}\n",
      "\n",
      "=== 开始高级并发测试 ===\n",
      "同时发送 5 个问题测试并发处理...\n",
      "✅ 问题3完成 (5.18s): 什么是JavaScript？\n",
      "✅ 问题1完成 (5.67s): 什么是Python？\n",
      "✅ 问题5完成 (7.07s): 什么是Rust？\n",
      "✅ 问题2完成 (7.75s): 什么是Java？\n"
>>>>>>> 7f5a145781e4be1df374c9d1fdb11b39af106008
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# 创建LLM实例\n",
    "llm = create_llm()\n",
    "\n",
    "# 查看配置状态\n",
    "print(\"=== LLM配置状态 ===\")\n",
    "status = llm.get_status()\n",
    "for key, value in status.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\n当前激活的fallback列表: {status['active_fallback_list']}\")\n",
    "print(f\"可用的providers: {status['available_providers']}\")\n",
    "print(f\"已初始化的clients: {status['initialized_clients']}\")"
=======
    "def advanced_concurrent_test():\n",
    "    \"\"\"高级并发测试：测试简化后的LLM并发处理\"\"\"\n",
    "    \n",
    "    # 重置实例确保干净状态\n",
    "    from llm_api.universal_llm import UniversalLLM\n",
    "    UniversalLLM.reset_instance()\n",
    "    \n",
    "    llm = create_llm(\"base\")  # 使用base配置，有更多可用的providers\n",
    "    \n",
    "    # 显示当前状态\n",
    "    status = llm.get_status()\n",
    "    print(\"=== 当前LLM状态 ===\")\n",
    "    print(f\"可用providers: {status['available_providers']}\")\n",
    "    print(f\"已初始化clients: {status['initialized_clients']}\")\n",
    "    print(f\"超时配置: {status['timeout_config']}\")\n",
    "    \n",
    "    # 创建5个不同的问题来测试并发处理\n",
    "    questions = [\n",
    "        \"什么是Python？\",\n",
    "        \"什么是Java？\", \n",
    "        \"什么是JavaScript？\",\n",
    "        \"什么是Go语言？\",\n",
    "        \"什么是Rust？\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n=== 开始高级并发测试 ===\")\n",
    "    print(f\"同时发送 {len(questions)} 个问题测试并发处理...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = []\n",
    "    \n",
    "    # 使用并发workers进行测试\n",
    "    with ThreadPoolExecutor(max_workers=len(questions)) as executor:\n",
    "        # 提交所有任务\n",
    "        future_to_question = {}\n",
    "        for i, question in enumerate(questions):\n",
    "            future = executor.submit(llm.generate, f\"{question}（简单回答，20字内）\", False)\n",
    "            future_to_question[future] = (i, question)\n",
    "        \n",
    "        # 收集结果\n",
    "        for future in as_completed(future_to_question):\n",
    "            question_index, question = future_to_question[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                completion_time = time.time() - start_time\n",
    "                results.append({\n",
    "                    'index': question_index,\n",
    "                    'question': question,\n",
    "                    'answer': result,\n",
    "                    'completion_time': completion_time,\n",
    "                    'provider': llm.current_provider\n",
    "                })\n",
    "                print(f\"✅ 问题{question_index+1}完成 ({completion_time:.2f}s): {question}\")\n",
    "            except Exception as e:\n",
    "                completion_time = time.time() - start_time\n",
    "                results.append({\n",
    "                    'index': question_index,\n",
    "                    'question': question,\n",
    "                    'error': str(e),\n",
    "                    'completion_time': completion_time\n",
    "                })\n",
    "                print(f\"❌ 问题{question_index+1}失败 ({completion_time:.2f}s): {e}\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    successful_count = len([r for r in results if 'answer' in r])\n",
    "    \n",
    "    print(f\"\\n=== 高级并发测试结果 ===\")\n",
    "    print(f\"总耗时: {total_time:.2f}秒\")\n",
    "    print(f\"成功完成: {successful_count}/{len(questions)}\")\n",
    "    if successful_count > 0:\n",
    "        print(f\"平均每个请求耗时: {total_time/len(questions):.2f}秒\")\n",
    "        print(f\"主要使用的provider: {llm.current_provider}\")\n",
    "    \n",
    "    # 按完成时间排序显示结果\n",
    "    results.sort(key=lambda x: x['completion_time'])\n",
    "    for result in results:\n",
    "        print(f\"问题{result['index']+1} ({result['completion_time']:.2f}s): {result['question']}\")\n",
    "        if 'answer' in result:\n",
    "            print(f\"  回答: {result['answer']}\")\n",
    "            print(f\"  Provider: {result.get('provider', 'unknown')}\")\n",
    "        else:\n",
    "            print(f\"  错误: {result['error']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 运行高级并发测试\n",
    "advanced_results = advanced_concurrent_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 高级并发测试：测试并发控制机制\n",
    "\n",
    "测试UniversalLLM内置的并发控制和排队机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ UniversalLLM 重构总结\n",
    "\n",
    "### 🔧 主要重构内容：\n",
    "\n",
    "#### 1. **移除过度设计的并发控制**\n",
    "- ❌ 原问题：复杂的 ConcurrencyManager 类，包含未使用的队列和跨进程信号量\n",
    "- ✅ 重构方案：使用简单的共享线程池进行超时控制\n",
    "\n",
    "#### 2. **简化单例模式**\n",
    "- ❌ 原问题：复杂的跨进程单例逻辑\n",
    "- ✅ 重构方案：简化为标准线程安全单例模式\n",
    "\n",
    "#### 3. **统一超时处理**\n",
    "- ❌ 原问题：三个不同的超时参数，使用不一致\n",
    "- ✅ 重构方案：使用 TimeoutProfile 数据类统一管理\n",
    "\n",
    "#### 4. **Provider调用映射化**\n",
    "- ❌ 原问题：使用 if/elif 分支处理不同 provider\n",
    "- ✅ 重构方案：使用字典映射 provider_type -> handler 函数\n",
    "\n",
    "#### 5. **抽象重试逻辑**\n",
    "- ❌ 原问题：重试逻辑写死在 generate 方法中\n",
    "- ✅ 重构方案：直接在 generate 方法中实现，逻辑更清晰\n",
    "\n",
    "#### 6. **使用 ProviderConfig 数据类**\n",
    "- ❌ 原问题：配置访问分散，属性重复获取\n",
    "- ✅ 重构方案：使用 dataclass 封装 provider 配置\n",
    "\n",
    "### 🧪 **代码优化效果**：\n",
    "- **代码行数**: 从 460 行减少到 285 行 (减少 38%)\n",
    "- **复杂度**: 大幅降低，移除了所有过度设计\n",
    "- **可读性**: 显著提升，逻辑更加直观\n",
    "- **性能**: 移除重复的 ThreadPoolExecutor 创建\n",
    "\n",
    "### 📋 **新的使用方式**：\n",
    "1. **简化的 API**: 保持向后兼容性\n",
    "2. **统一超时**: 使用 TimeoutProfile 管理\n",
    "3. **Provider 映射**: 更容易扩展新的 provider\n",
    "\n",
    "### 🎯 **测试验证**：\n",
    "- ✅ 基本功能：正常工作\n",
    "- ✅ Fallback 机制：自动切换正常\n",
    "- ✅ 并发处理：多线程测试通过\n",
    "- ✅ API 兼容性：现有代码无需修改\n",
    "\n",
    "---\n",
    "**✨ UniversalLLM 重构完成，代码更简洁高效！**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 并发测试状态信息 ===\n",
      "使用配置的fallback顺序: ['gpt_light', 'gpt_free', 'ollama']\n",
      "可用providers: ['gpt_light', 'gpt_free', 'gpt_pro', 'ollama']\n",
      "已初始化clients: ['gpt_light', 'gpt_free', 'gpt_pro']\n",
      "超时配置: {'connection': 10, 'read': 30, 'total': 120}\n",
      "\n",
      "=== 开始并发测试 ===\n",
      "同时发送 2 个问题测试并发处理...\n",
      "✅ 问题完成: 用一句话介绍Python的特点...\n",
      "✅ 问题完成: 简单解释什么是机器学习...\n",
      "\n",
      "=== 并发测试结果 ===\n",
      "总耗时: 14.78秒\n",
      "成功完成: 2/2\n",
      "\n",
      "--- 问题 1 ---\n",
      "问题: 用一句话介绍Python的特点\n",
      "回答: **简洁易学、功能强大、应用广泛。**\n",
      "使用Provider: gpt_light\n",
      "用时: 12.30秒\n",
      "\n",
      "--- 问题 2 ---\n",
      "问题: 简单解释什么是机器学习\n",
      "回答: 简单来说，**机器学习就是让电脑通过“看”大量数据，自己“学习”和“发现”规律，而不是我们一步步地告诉它所有规则。**\n",
      "\n",
      "想象一下，你教一个小孩子认识猫和狗。你不会写一个很长的说明书告诉他：“如果它有尖耳朵、胡须、喵喵叫，那就是猫。”\n",
      "\n",
      "而是你给他看很多很多猫的照片和视频，告诉他：“这是猫。” 再给他看很多很多狗的照片和视频，告诉他：“这是狗。”\n",
      "\n",
      "慢慢地，小孩子自己就会总结出猫和狗的特征，以后再看到新的动物，他就能分辨出是猫还是狗了。\n",
      "\n",
      "**机器学习的原理也差不多：**\n",
      "\n",
      "1.  **喂数据（“看”）：** 我们给电脑喂入（输入）大量的数据（比如猫和狗的照片，或者用户的购买记录、邮件内容等）。\n",
      "2.  **找规律（“学习”）：** 电脑会通过复杂的算法，自己从这些数据中找出隐藏的模式和规律。它不会被明确告知“猫有胡须”，而是通过观察大量猫的图片，自己“发现”了共同的特征。\n",
      "3.  **做预测/判断（“分辨”）：** 一旦它“学”会了这些规律，当遇到新的、它没见过的数据时，它就能根据学到的规律做出判断或预测。\n",
      "\n",
      "**举几个例子：**\n",
      "\n",
      "*   **垃圾邮件识别：** 你不需要告诉电脑垃圾邮件有哪些固定词语。你只需要给它看成千上万封邮件，并告诉它哪些是垃圾邮件，哪些不是。电脑自己就能学到垃圾邮件的特征，以后就能自动帮你过滤。\n",
      "*   **商品推荐：** 比如你在淘宝或Netflix上，它会推荐你可能喜欢的商品或电影。它就是分析了你的历史购买/观看记录，以及其他用户的行为，从而预测你可能喜欢什么。\n",
      "*   **人脸识别：** 你给它看很多人的照片并告诉它照片里是谁，它就能学会识别不同的人。\n",
      "\n",
      "所以，机器学习的核心就是让电脑拥有**从经验中学习**的能力，让它变得更“聪明”，能够处理那些我们很难用传统方法（写死规则）去解决的问题。\n",
      "使用Provider: gpt_light\n",
      "用时: 14.78秒\n",
      "\n",
      "=== 最终状态 ===\n",
      "当前provider: gpt_light\n",
      "超时配置: {'connection': 10, 'read': 30, 'total': 120}\n"
     ]
    }
   ],
   "source": [
    "def concurrent_llm_test():\n",
    "    \"\"\"并发测试：同时问两个不同问题 - 测试简化后的并发处理\"\"\"\n",
    "    \n",
    "    # 重置实例确保干净状态\n",
    "    from llm_api.universal_llm import UniversalLLM\n",
    "    UniversalLLM.reset_instance()\n",
    "    \n",
    "    # 创建LLM实例\n",
    "    llm = create_llm(\"base\")  # 使用base配置，有更多providers可用\n",
    "    \n",
    "    print(\"=== 并发测试状态信息 ===\")\n",
    "    status = llm.get_status()\n",
    "    print(f\"使用配置的fallback顺序: {status['active_fallback_list']}\")\n",
    "    print(f\"可用providers: {status['available_providers']}\")\n",
    "    print(f\"已初始化clients: {status['initialized_clients']}\")\n",
    "    print(f\"超时配置: {status['timeout_config']}\")\n",
    "    \n",
    "    # 定义两个不同的问题\n",
    "    questions = [\n",
    "        \"用一句话介绍Python的特点\",\n",
    "        \"简单解释什么是机器学习\"\n",
    "    ]\n",
    "    \n",
    "    # 用于存储结果的列表\n",
    "    results = []\n",
    "    \n",
    "    # 使用ThreadPoolExecutor进行并发调用\n",
    "    print(f\"\\n=== 开始并发测试 ===\")\n",
    "    print(f\"同时发送 {len(questions)} 个问题测试并发处理...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        # 提交任务\n",
    "        future_to_question = {\n",
    "            executor.submit(llm.generate, question, False): question \n",
    "            for question in questions\n",
    "        }\n",
    "        \n",
    "        # 收集结果\n",
    "        for future in as_completed(future_to_question):\n",
    "            question = future_to_question[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                end_time = time.time()\n",
    "                results.append({\n",
    "                    'question': question,\n",
    "                    'answer': result,\n",
    "                    'provider': llm.current_provider,\n",
    "                    'duration': end_time - start_time\n",
    "                })\n",
    "                print(f\"✅ 问题完成: {question[:20]}...\")\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    'question': question,\n",
    "                    'error': str(e),\n",
    "                    'duration': time.time() - start_time\n",
    "                })\n",
    "                print(f\"❌ 问题失败: {question[:20]}... - {e}\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    successful_count = len([r for r in results if 'answer' in r])\n",
    "    \n",
    "    print(f\"\\n=== 并发测试结果 ===\")\n",
    "    print(f\"总耗时: {total_time:.2f}秒\")\n",
    "    print(f\"成功完成: {successful_count}/{len(questions)}\")\n",
    "    \n",
    "    # 显示每个问题的结果\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\n--- 问题 {i} ---\")\n",
    "        print(f\"问题: {result['question']}\")\n",
    "        if 'answer' in result:\n",
    "            print(f\"回答: {result['answer']}\")\n",
    "            print(f\"使用Provider: {result.get('provider', 'unknown')}\")\n",
    "        else:\n",
    "            print(f\"错误: {result.get('error', 'unknown error')}\")\n",
    "        print(f\"用时: {result['duration']:.2f}秒\")\n",
    "    \n",
    "    # 显示最终状态\n",
    "    final_status = llm.get_status()\n",
    "    print(f\"\\n=== 最终状态 ===\")\n",
    "    print(f\"当前provider: {final_status.get('current_provider')}\")\n",
    "    print(f\"超时配置: {final_status.get('timeout_config')}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 运行并发测试\n",
    "concurrent_results = concurrent_llm_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UniversalLLM 多轮对话功能使用指南 ===\n",
      "\n",
      "### 🆕 新功能：多轮对话支持\n",
      "\n",
      "#### 1. **基本用法对比**:\n",
      "\n",
      "**单轮对话 (保持不变)**:\n",
      "```python\n",
      "llm = create_llm(\"base\")\n",
      "response = llm.generate(\"你好\")  # 单次问答\n",
      "```\n",
      "\n",
      "**多轮对话 (新功能)**:\n",
      "```python\n",
      "llm = create_llm(\"base\")\n",
      "messages = [\n",
      "    {\"role\": \"user\", \"content\": \"你好\"},\n",
      "    {\"role\": \"assistant\", \"content\": \"你好！有什么可以帮助你的？\"},\n",
      "    {\"role\": \"user\", \"content\": \"介绍一下Python\"}\n",
      "]\n",
      "response = llm.chat(messages)  # 基于历史的多轮对话\n",
      "```\n",
      "\n",
      "#### 2. **支持的消息角色**:\n",
      "- `user`: 用户消息\n",
      "- `assistant`: 助手回复 \n",
      "- `system`: 系统设定 (如角色设定)\n",
      "\n",
      "#### 3. **API后端支持**:\n",
      "- **OpenAI兼容**: 使用 `/chat/completions` 接口，完全支持messages格式\n",
      "- **Ollama**: \n",
      "  - 单轮对话: 使用 `/api/generate` 接口 (传统prompt方式)\n",
      "  - 多轮对话: 使用 `/api/chat` 接口 (messages格式)\n",
      "\n",
      "#### 4. **向后兼容性**:\n",
      "- ✅ 现有的 `generate()` 方法完全不变\n",
      "- ✅ 现有代码无需修改\n",
      "- ✅ 新的 `chat()` 方法为可选功能\n",
      "\n",
      "#### 5. **使用场景**:\n",
      "- **单轮对话**: 简单问答、文本生成、翻译等\n",
      "- **多轮对话**: 对话助手、教学辅导、上下文相关的问答\n",
      "\n",
      "#### 6. **最佳实践**:\n",
      "- 适当使用系统消息设定助手角色\n",
      "- 管理对话历史长度，避免过长\n",
      "- 单次简单任务仍可使用 `generate()`\n",
      "- 需要上下文的复杂对话使用 `chat()`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== UniversalLLM 多轮对话功能使用指南 ===\")\n",
    "\n",
    "print(\"\"\"\n",
    "### 🆕 新功能：多轮对话支持\n",
    "\n",
    "#### 1. **基本用法对比**:\n",
    "\n",
    "**单轮对话 (保持不变)**:\n",
    "```python\n",
    "llm = create_llm(\"base\")\n",
    "response = llm.generate(\"你好\")  # 单次问答\n",
    "```\n",
    "\n",
    "**多轮对话 (新功能)**:\n",
    "```python\n",
    "llm = create_llm(\"base\")\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"你好\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"你好！有什么可以帮助你的？\"},\n",
    "    {\"role\": \"user\", \"content\": \"介绍一下Python\"}\n",
    "]\n",
    "response = llm.chat(messages)  # 基于历史的多轮对话\n",
    "```\n",
    "\n",
    "#### 2. **支持的消息角色**:\n",
    "- `user`: 用户消息\n",
    "- `assistant`: 助手回复 \n",
    "- `system`: 系统设定 (如角色设定)\n",
    "\n",
    "#### 3. **API后端支持**:\n",
    "- **OpenAI兼容**: 使用 `/chat/completions` 接口，完全支持messages格式\n",
    "- **Ollama**: \n",
    "  - 单轮对话: 使用 `/api/generate` 接口 (传统prompt方式)\n",
    "  - 多轮对话: 使用 `/api/chat` 接口 (messages格式)\n",
    "\n",
    "#### 4. **向后兼容性**:\n",
    "- ✅ 现有的 `generate()` 方法完全不变\n",
    "- ✅ 现有代码无需修改\n",
    "- ✅ 新的 `chat()` 方法为可选功能\n",
    "\n",
    "#### 5. **使用场景**:\n",
    "- **单轮对话**: 简单问答、文本生成、翻译等\n",
    "- **多轮对话**: 对话助手、教学辅导、上下文相关的问答\n",
    "\n",
    "#### 6. **最佳实践**:\n",
    "- 适当使用系统消息设定助手角色\n",
    "- 管理对话历史长度，避免过长\n",
    "- 单次简单任务仍可使用 `generate()`\n",
    "- 需要上下文的复杂对话使用 `chat()`\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 使用指南和API对比\n",
    "\n",
    "新的多轮对话功能使用指南"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 创建简易对话助手 ===\n",
      "对话助手初始化完成，使用配置: base\n",
      "可用providers: ['gpt_light', 'gpt_free', 'gpt_pro', 'ollama']\n",
      "系统消息已设定: 你是一个友好的Python编程助手，专门帮助用户学习Python编程。请用简洁易懂的语言回答问题。\n",
      "\n",
      "=== 对话演示 ===\n",
      "\\n--- 对话 1 ---\n",
      "用户: Hello! 我想学习Python，应该从哪里开始？\n",
      "助手: Hello! 很高兴你想学习Python！Python是一种非常棒的语言，因为它简洁、易读、功能强大，非常适合初学者。\n",
      "\n",
      "要开始学习Python，你可以按照以下步骤来：\n",
      "\n",
      "### 1. 准备环境 (安装Python)\n",
      "\n",
      "*   **下载并安装Python：** 访问 [python.org](https://www.python.org/)，下载最新稳定版的Python。在安装时，**请务必勾选 \"Add Python X.X to PATH\"**（将Python添加到系统路径），这样你就能在任何地方运行Python命令了。\n",
      "*   **选择一个代码编辑器：**\n",
      "    *   **VS Code (Visual Studio Code):** 推荐！它功能强大，有丰富的插件，对Python支持非常好，而且是免费的。\n",
      "    *   **PyCharm Community Edition:** 专业的Python IDE，功能更全面，但对于初学者来说可能稍微复杂一些。\n",
      "    *   **IDLE (自带):** Python安装后会自带一个简单的集成开发环境IDLE，你可以用它来运行一些小代码，但通常不用于大型项目。\n",
      "\n",
      "### 2. 学习基础语法 (核心概念)\n",
      "\n",
      "这是最重要的部分！你需要理解编程的基本逻辑和Python的语法规则。\n",
      "\n",
      "*   **“Hello World!”：** 这是你写的第一行代码，用来确认环境是否配置成功。\n",
      "    ```python\n",
      "    print(\"Hello, World!\")\n",
      "    ```\n",
      "*   **变量 (Variables)：** 用来存储数据的容器。\n",
      "    ```python\n",
      "    name = \"Alice\"\n",
      "    age = 30\n",
      "    ```\n",
      "*   **数据类型 (Data Types)：** 了解Python中常见的数据类型，如：\n",
      "    *   **整型 (int)：** `10`, `200`\n",
      "    *   **浮点型 (float)：** `3.14`, `0.5`\n",
      "    *   **字符串 (str)：** `\"Hello\"`, `'Python'`\n",
      "    *   **布尔型 (bool)：** `True`, `False`\n",
      "*   **运算符 (Operators)：** 进行数学计算、比较和逻辑判断。\n",
      "    *   算术运算符：`+`, `-`, `*`, `/`, `%`\n",
      "    *   比较运算符：`==`, `!=`, `>`, `<`, `>=`, `<=`\n",
      "    *   逻辑运算符：`and`, `or`, `not`\n",
      "*   **输入与输出 (Input & Output)：**\n",
      "    *   `print()`：将信息显示到屏幕。\n",
      "    *   `input()`：从用户那里获取输入。\n",
      "*   **条件语句 (Conditional Statements - `if`, `elif`, `else`)：** 根据条件执行不同的代码块。\n",
      "    ```python\n",
      "    if age >= 18:\n",
      "        print(\"成年人\")\n",
      "    else:\n",
      "        print(\"未成年人\")\n",
      "    ```\n",
      "*   **循环 (Loops - `for`, `while`)：** 重复执行某段代码。\n",
      "    ```python\n",
      "    # for 循环\n",
      "    for i in range(5): # 0, 1, 2, 3, 4\n",
      "        print(i)\n",
      "\n",
      "    # while 循环\n",
      "    count = 0\n",
      "    while count < 3:\n",
      "        print(\"Hello\")\n",
      "        count += 1\n",
      "    ```\n",
      "*   **函数 (Functions)：** 将一段可重用的代码封装起来，提高代码的组织性和复用性。\n",
      "    ```python\n",
      "    def greet(name):\n",
      "        return f\"你好, {name}!\"\n",
      "\n",
      "    message = greet(\"小明\")\n",
      "    print(message)\n",
      "    ```\n",
      "*   **数据结构 (Data Structures)：** 学习如何组织和存储多个数据。\n",
      "    *   **列表 (List)：** 有序、可变（可修改）的集合。`[1, 2, 3]`\n",
      "    *   **元组 (Tuple)：** 有序、不可变（不可修改）的集合。`(1, 2, 3)`\n",
      "    *   **字典 (Dictionary)：** 键值对的集合，无序。`{'name': 'Alice', 'age': 30}`\n",
      "    *   **集合 (Set)：** 无序、不重复元素的集合。`{1, 2, 3}`\n",
      "\n",
      "### 3. 实践与练习 (非常重要!)\n",
      "\n",
      "学习编程最有效的方式就是多动手、多练习！\n",
      "\n",
      "*   **解决小问题：** 尝试编写小程序来解决一些简单的逻辑问题（比如：计算器、猜数字游戏、判断闰年等）。\n",
      "*   **阅读代码：** 看看别人写的Python代码，了解不同的编程风格和技巧。\n",
      "*   **调试 (Debugging)：** 学会如何找到并修复代码中的错误。\n",
      "\n",
      "### 4. 推荐学习资源\n",
      "\n",
      "*   **在线互动教程：**\n",
      "    *   **Codecademy (Python 3):** 互动式学习，边学边练。\n",
      "    *   **FreeCodeCamp (Scientific Computing with Python):** 免费且内容丰富，项目导向。\n",
      "*   **视频教程：**\n",
      "    *   **Bilibili、YouTube：** 搜索“Python 入门教程”，有很多优秀的免费课程。\n",
      "    *   **Coursera、Udemy：** 也有很多高质量的付费课程，通常更系统。\n",
      "*   **书籍：**\n",
      "    *   **《Python编程从入门到实践》 (Python Crash Course):** 非常适合初学者，理论结合项目。\n",
      "    *   **《笨办法学Python》 (Learn Python the Hard Way):** 通过大量练习来学习。\n",
      "    *   **《Python自动化办公——把繁琐工作交给程序》 (Automate the Boring Stuff with Python):** 实用性强，通过实际项目学习。\n",
      "\n",
      "### 学习建议：\n",
      "\n",
      "*   **从小处着手：** 不要试图一次学完所有东西，从基础开始，循序渐进。\n",
      "*   **保持好奇心：** 遇到不理解的概念，多查资料，多问。\n",
      "*   **坚持不懈：** 编程是一项技能，需要时间和练习才能掌握。\n",
      "*   **享受过程：** 探索编程的乐趣，用代码解决实际问题会非常有成就感！\n",
      "\n",
      "如果你在学习过程中有任何具体的问题，随时都可以问我！祝你学习愉快！\n",
      "\\n--- 对话 2 ---\n",
      "用户: 那你推荐哪些学习资源呢？\n",
      "助手: 好的！针对Python初学者，我为你精心挑选了一些非常棒的学习资源。它们各有侧重，你可以根据自己的学习习惯和偏好来选择。\n",
      "\n",
      "### 1. 在线互动学习平台 (推荐给喜欢动手、即时反馈的你)\n",
      "\n",
      "*   **Codecademy (Python 3)**\n",
      "    *   **优点：** 互动性极强，边学边练，即时反馈，界面友好，对零基础非常友好。它会一步步引导你完成代码，非常适合培养编程思维。\n",
      "    *   **缺点：** 免费内容有限，更深入的课程可能需要付费。\n",
      "    *   **推荐理由：** 如果你喜欢通过实践来学习，这是绝佳的起点。\n",
      "\n",
      "*   **FreeCodeCamp (Scientific Computing with Python)**\n",
      "    *   **优点：** 完全免费，课程内容扎实，以项目为导向，学完基础后会让你做一些实际的小项目来巩固知识。社区活跃。\n",
      "    *   **缺点：** 课程节奏可能比Codecademy略快一点点。\n",
      "    *   **推荐理由：** 高质量的免费资源，项目导向的学习方式能让你更快地感受到编程的乐趣和实用性。\n",
      "\n",
      "*   **W3Schools Python Tutorial**\n",
      "    *   **优点：** 简洁明了，易于查找特定语法点，每个知识点都有“Try it Yourself”功能，可以快速测试代码。\n",
      "    *   **缺点：** 更像是一个参考手册，系统性学习不如前两者。\n",
      "    *   **推荐理由：** 适合作为快速查询和验证小代码片段的工具。\n",
      "\n",
      "### 2. 经典入门书籍 (推荐给喜欢系统学习、深入理解的你)\n",
      "\n",
      "*   **《Python编程从入门到实践》 (Python Crash Course)**\n",
      "    *   **优点：** 被誉为Python入门的“圣经”之一。前半部分详细讲解Python基础，后半部分通过三个大型项目（游戏、数据可视化、Web应用）巩固所学，理论与实践结合得非常好。\n",
      "    *   **推荐理由：** 内容系统全面，项目实用有趣，能让你真正动手做出东西来。\n",
      "\n",
      "*   **《Python自动化办公——把繁琐工作交给程序》 (Automate the Boring Stuff with Python)**\n",
      "    *   **优点：** 非常实用！通过大量实际案例（如处理Excel、PDF、邮件、网页抓取等）来学习Python。能让你体会到Python在日常工作中的巨大价值。\n",
      "    *   **推荐理由：** 如果你对自动化工作、提高效率感兴趣，这本书能给你很大的动力和成就感。\n",
      "\n",
      "*   **《笨办法学Python》 (Learn Python the Hard Way)**\n",
      "    *   **优点：** 强调“动手敲代码”和“理解代码”的重要性，通过大量的练习来掌握基础。\n",
      "    *   **缺点：** 风格比较直接，可能对某些初学者来说会觉得有点枯燥。\n",
      "    *   **推荐理由：** 如果你喜欢通过大量重复练习来巩固知识，这本书会很适合你。\n",
      "\n",
      "### 3. 视频教程 (推荐给喜欢听讲、视觉学习的你)\n",
      "\n",
      "*   **Bilibili (B站)**\n",
      "    *   **优点：** 有大量免费的Python入门教程，很多UP主讲得非常生动有趣，你可以找到不同风格的老师。例如搜索“**Python零基础入门**”、“**Python教程**”等。\n",
      "    *   **推荐UP主/机构 (可以自行搜索)：** 尚硅谷、黑马程序员、清华大学计算机系、小甲鱼等，都提供高质量的免费课程。\n",
      "    *   **推荐理由：** 资源丰富，选择多样，可以找到最适合你学习节奏和风格的视频。\n",
      "\n",
      "*   **YouTube (英文资源)**\n",
      "    *   **优点：** 国际上顶级的Python教学资源，例如**Corey Schafer**、**Mosh Hamedani**等频道，内容质量非常高，更新及时。\n",
      "    *   **推荐理由：** 如果你的英文不错，这些资源能让你接触到更广泛、更前沿的编程知识。\n",
      "\n",
      "*   **Coursera / Udemy / edX**\n",
      "    *   **优点：** 很多大学和专业机构提供的系统性课程，质量有保证，通常包含作业和证书。例如Coursera上的“Python for Everybody Specialization”（密歇根大学）。\n",
      "    *   **缺点：** 大部分是付费课程，但有些课程可以申请助学金或免费旁听。\n",
      "    *   **推荐理由：** 如果你追求更体系化、更专业的学习体验，这些平台是不错的选择。\n",
      "\n",
      "### 4. 实践练习平台 (巩固所学，提升能力)\n",
      "\n",
      "*   **LeetCode (力扣)** / **HackerRank** / **Codewars**\n",
      "    *   **优点：** 提供大量的编程题目，从简单到复杂，可以帮助你巩固语法、锻炼算法思维。\n",
      "    *   **推荐理由：** 学习编程，光看是没用的，一定要多写多练。这些平台能提供源源不断的练习题。建议从“Easy”级别的题目开始。\n",
      "\n",
      "### 学习建议：\n",
      "\n",
      "1.  **选择1-2个主要资源：** 不用贪多，选择一个你最喜欢的学习平台/书籍/视频课程作为主线。\n",
      "2.  **多动手：** 跟着教程敲代码，不要只是看。遇到问题自己尝试解决，这是进步最快的方式。\n",
      "3.  **理解而非记忆：** 编程不是死记硬背，而是理解逻辑和解决问题的方法。\n",
      "4.  **坚持和耐心：** 编程学习是一个循序渐进的过程，遇到困难很正常，保持耐心，多尝试，你一定能克服。\n",
      "5.  **利用搜索引擎：** 遇到任何报错或不理解的概念，直接复制粘贴到Google/百度搜索，通常都能找到答案。\n",
      "\n",
      "希望这些资源能帮助你开启愉快的Python学习之旅！如果你在学习过程中遇到任何具体问题，随时都可以问我！\n",
      "\\n--- 对话 3 ---\n",
      "用户: 我应该多长时间能够掌握基础？\n",
      "助手: 很高兴你问这个问题！这是一个非常常见且重要的问题。\n",
      "\n",
      "要回答“多长时间能够掌握基础”，其实**没有一个标准答案，因为它因人而异**，取决于你的：\n",
      "\n",
      "1.  **投入时间：** 你每天或每周能投入多少时间学习和练习？\n",
      "2.  **学习方式：** 你是喜欢阅读、看视频、还是动手实践？\n",
      "3.  **学习效率：** 你是否能专注学习，并及时消化吸收新知识？\n",
      "4.  **背景知识：** 你是否有其他编程语言的基础，或者逻辑思维能力较强？\n",
      "5.  **对“掌握基础”的定义：** 你认为掌握基础是到什么程度？\n",
      "\n",
      "### 对“掌握基础”的定义：\n",
      "\n",
      "通常，我们说的“掌握Python基础”是指你能够：\n",
      "\n",
      "*   **理解并熟练使用** Python 的核心语法元素：\n",
      "    *   变量、数据类型 (整型、浮点型、字符串、布尔型)\n",
      "    *   运算符 (算术、比较、逻辑)\n",
      "    *   输入和输出 (`print()`, `input()`)\n",
      "    *   条件语句 (`if`, `elif`, `else`)\n",
      "    *   循环 (`for`, `while`)\n",
      "    *   函数 (`def`)\n",
      "    *   常用的数据结构 (列表 `list`, 元组 `tuple`, 字典 `dict`, 集合 `set`)\n",
      "*   **能够阅读** 简单的 Python 代码。\n",
      "*   **能够独立编写** 解决简单逻辑问题的小程序（比如计算器、猜数字游戏、简单的文件读写等）。\n",
      "*   **知道如何查找资料和调试** 简单的错误。\n",
      "\n",
      "### 预估时间：\n",
      "\n",
      "根据不同的投入程度，我可以给你一个大致的时间范围：\n",
      "\n",
      "1.  **高强度学习 (每天 3-4 小时或更多)：**\n",
      "    *   如果你能每天投入大量时间（例如，脱产学习或全职自学），并且保持高度专注和大量的动手练习，那么 **2-4 周** 就可以基本掌握上述核心基础。你会很快进入到写一些简单实用程序并解决问题的阶段。\n",
      "\n",
      "2.  **中等强度学习 (每天 1-2 小时)：**\n",
      "    *   如果你是上班族或学生，每天能稳定抽出 1-2 小时学习和练习，那么大约需要 **1-3 个月** 来掌握Python基础。这个节奏比较常见，也更容易坚持下来。\n",
      "\n",
      "3.  **低强度学习 (每周 几小时)：**\n",
      "    *   如果你只能在周末或零碎时间学习，每周总共只有几个小时，那么可能需要 **3-6 个月甚至更久** 才能掌握基础。这种情况下，保持学习的连贯性会比较重要，避免学了就忘。\n",
      "\n",
      "### 最重要的建议：\n",
      "\n",
      "**“掌握”不是看书或看视频的时间，而是你真正动手写代码的时间。**\n",
      "\n",
      "*   **多动手，多练习：** 这是掌握编程基础最关键的一点。每学一个新概念，就写几行代码去实践它。\n",
      "*   **解决问题：** 尝试用Python解决你身边的实际问题，哪怕是很小的自动化任务。\n",
      "*   **坚持不懈：** 遇到困难时不要气馁，查资料、提问、尝试不同的方法。\n",
      "*   **不要只看，要写：** 很多初学者容易陷入“教程陷阱”，只看教程而不动手，这样永远无法真正掌握。\n",
      "\n",
      "所以，别担心具体的时间长度，更重要的是**保持学习的连贯性，并尽可能多地动手实践**。相信你很快就能掌握Python的基础，并开始享受编程的乐趣！\n",
      "\\n=== 对话统计 ===\n",
      "total_messages: 7\n",
      "user_messages: 3\n",
      "assistant_messages: 3\n",
      "system_messages: 1\n",
      "current_provider: gpt_light\n",
      "\\n✅ 多轮对话助手演示完成！\n"
     ]
    }
   ],
   "source": [
    "class SimpleChatBot:\n",
    "    \"\"\"简单的多轮对话助手\"\"\"\n",
    "    \n",
    "    def __init__(self, config_name=\"base\"):\n",
    "        # 重置实例确保干净状态\n",
    "        from llm_api.universal_llm import UniversalLLM\n",
    "        UniversalLLM.reset_instance()\n",
    "        \n",
    "        self.llm = create_llm(config_name)\n",
    "        self.conversation_history = []\n",
    "        print(f\"对话助手初始化完成，使用配置: {config_name}\")\n",
    "        print(f\"可用providers: {self.llm.get_status()['available_providers']}\")\n",
    "    \n",
    "    def add_system_message(self, content):\n",
    "        \"\"\"添加系统消息设定助手角色\"\"\"\n",
    "        self.conversation_history.append({\"role\": \"system\", \"content\": content})\n",
    "        print(f\"系统消息已设定: {content}\")\n",
    "    \n",
    "    def chat(self, user_input, verbose=False):\n",
    "        \"\"\"进行一轮对话\"\"\"\n",
    "        # 添加用户消息\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        \n",
    "        try:\n",
    "            # 获取助手回复\n",
    "            response = self.llm.chat(self.conversation_history.copy(), verbose=verbose)\n",
    "            \n",
    "            # 添加助手回复到历史\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "            \n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"对话失败: {e}\")\n",
    "            # 如果失败，移除刚添加的用户消息\n",
    "            self.conversation_history.pop()\n",
    "            return None\n",
    "    \n",
    "    def get_conversation_summary(self):\n",
    "        \"\"\"获取对话摘要\"\"\"\n",
    "        user_messages = len([msg for msg in self.conversation_history if msg[\"role\"] == \"user\"])\n",
    "        assistant_messages = len([msg for msg in self.conversation_history if msg[\"role\"] == \"assistant\"])\n",
    "        system_messages = len([msg for msg in self.conversation_history if msg[\"role\"] == \"system\"])\n",
    "        \n",
    "        return {\n",
    "            \"total_messages\": len(self.conversation_history),\n",
    "            \"user_messages\": user_messages,\n",
    "            \"assistant_messages\": assistant_messages,\n",
    "            \"system_messages\": system_messages,\n",
    "            \"current_provider\": self.llm.current_provider\n",
    "        }\n",
    "    \n",
    "    def clear_history(self, keep_system=True):\n",
    "        \"\"\"清除对话历史\"\"\"\n",
    "        if keep_system:\n",
    "            # 保留系统消息\n",
    "            self.conversation_history = [msg for msg in self.conversation_history if msg[\"role\"] == \"system\"]\n",
    "        else:\n",
    "            self.conversation_history = []\n",
    "        print(\"对话历史已清除\")\n",
    "\n",
    "# 创建对话助手实例并演示使用\n",
    "print(\"=== 创建简易对话助手 ===\")\n",
    "chatbot = SimpleChatBot(\"base\")\n",
    "\n",
    "# 设定助手角色\n",
    "chatbot.add_system_message(\"你是一个友好的Python编程助手，专门帮助用户学习Python编程。请用简洁易懂的语言回答问题。\")\n",
    "\n",
    "print(\"\\n=== 对话演示 ===\")\n",
    "\n",
    "# 第一轮对话\n",
    "print(\"\\\\n--- 对话 1 ---\")\n",
    "response1 = chatbot.chat(\"Hello! 我想学习Python，应该从哪里开始？\")\n",
    "if response1:\n",
    "    print(f\"用户: Hello! 我想学习Python，应该从哪里开始？\")\n",
    "    print(f\"助手: {response1}\")\n",
    "\n",
    "# 第二轮对话\n",
    "print(\"\\\\n--- 对话 2 ---\")\n",
    "response2 = chatbot.chat(\"那你推荐哪些学习资源呢？\")\n",
    "if response2:\n",
    "    print(f\"用户: 那你推荐哪些学习资源呢？\")\n",
    "    print(f\"助手: {response2}\")\n",
    "\n",
    "# 第三轮对话\n",
    "print(\"\\\\n--- 对话 3 ---\")\n",
    "response3 = chatbot.chat(\"我应该多长时间能够掌握基础？\")\n",
    "if response3:\n",
    "    print(f\"用户: 我应该多长时间能够掌握基础？\")\n",
    "    print(f\"助手: {response3}\")\n",
    "\n",
    "# 显示对话统计\n",
    "print(\"\\\\n=== 对话统计 ===\")\n",
    "summary = chatbot.get_conversation_summary()\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\\\n✅ 多轮对话助手演示完成！\")"
>>>>>>> 7f5a145781e4be1df374c9d1fdb11b39af106008
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## 2. 基本文本生成测试"
=======
    "## 9. 简易对话助手演示\n",
    "\n",
    "演示如何使用多轮对话功能创建一个简单的对话助手"
>>>>>>> 7f5a145781e4be1df374c9d1fdb11b39af106008
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": null,
>>>>>>> 7f5a145781e4be1df374c9d1fdb11b39af106008
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "=== 基本文本生成测试 ===\n",
      "使用 gpt_free 调用...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ gpt_free 调用成功\n",
      "\n",
      "✅ 测试成功！\n",
      "回复: 1+1=2。\n",
      "使用的provider: gpt_free\n"
=======
      "=== 多轮对话测试 ===\n",
      "使用的fallback列表: ['gpt_light', 'gpt_free', 'ollama']\n",
      "\n",
      "--- 第1轮对话 ---\n",
      "Using gpt_light (attempt 1/3)...\n",
      "✅ gpt_light succeeded\n",
      "用户: 你好！我想了解一下Python编程语言。\n",
      "助手: 你好！很高兴为你介绍Python编程语言。\n",
      "\n",
      "Python是一种**高级（High-level）**、**解释型（Interpreted）**、**通用（General-purpose）**的编程语言，由Guido van Rossum在1990年代初设计。它以其**简洁明了的语法**和**强大的功能**而闻名，是目前世界上最流行、最受喜爱的编程语言之一。\n",
      "\n",
      "### Python的主要特点：\n",
      "\n",
      "1.  **易学易用（Easy to Learn and Use）**：\n",
      "    *   Python的语法非常接近自然语言，代码可读性强，学习曲线平缓。\n",
      "    *   它强制使用缩进（而不是大括号）来表示代码块，这使得代码结构清晰。\n",
      "    *   它适合初学者入门，也适合专业开发者快速开发。\n",
      "\n",
      "2.  **开源免费（Open Source and Free）**：\n",
      "    *   Python是开源的，任何人都可以免费使用、分发和修改它。\n",
      "\n",
      "3.  **高级语言（High-Level Language）**：\n",
      "    *   你不需要关心内存管理等底层细节，Python会自动处理，这让开发者可以专注于解决问题本身。\n",
      "\n",
      "4.  **解释型语言（Interpreted Language）**：\n",
      "    *   Python代码在运行前不需要编译。这意味着你可以直接运行源代码，这加快了开发过程中的测试和调试。\n",
      "\n",
      "5.  **跨平台（Cross-Platform）**：\n",
      "    *   Python可以在多种操作系统上运行，如Windows、macOS、Linux等。你编写的Python代码在这些系统上通常无需修改就能运行。\n",
      "\n",
      "6.  **面向对象（Object-Oriented）**：\n",
      "    *   Python支持面向对象编程（OOP）范式，这使得代码模块化、可复用，并易于维护。\n",
      "\n",
      "7.  **丰富的库和框架（Rich Standard Library and Ecosystem）**：\n",
      "    *   Python拥有庞大而活跃的社区，开发了海量的第三方库和框架，涵盖了从数据处理到Web开发，从机器学习到科学计算的各个领域。这些库极大地扩展了Python的功能。\n",
      "\n",
      "### Python的主要应用领域：\n",
      "\n",
      "Python的应用非常广泛，几乎无处不在：\n",
      "\n",
      "1.  **Web开发（Web Development）**：\n",
      "    *   使用Django、Flask等框架可以快速构建高性能的网站和Web应用。\n",
      "\n",
      "2.  **数据科学、机器学习与人工智能（Data Science, Machine Learning & AI）**：\n",
      "    *   这是Python最热门的应用领域之一。拥有NumPy、Pandas（数据处理）、Matplotlib、Seaborn（数据可视化）、Scikit-learn（机器学习）、TensorFlow、PyTorch（深度学习）等强大库，Python是数据科学家和AI工程师的首选语言。\n",
      "\n",
      "3.  **自动化与脚本（Automation & Scripting）**：\n",
      "    *   Python可以用于编写各种自动化脚本，如文件操作、系统管理、网络爬虫、日常任务自动化等。\n",
      "\n",
      "4.  **桌面应用开发（Desktop Applications）**：\n",
      "    *   虽然不如Web和数据科学那么流行，但Python也可以用于开发桌面GUI应用（如使用PyQt、Tkinter）。\n",
      "\n",
      "5.  **科学计算（Scientific Computing）**：\n",
      "    *   在数学、物理、化学、生物等科学领域进行复杂的计算和模拟。\n",
      "\n",
      "6.  **游戏开发（Game Development）**：\n",
      "    *   使用Pygame等库可以开发简单的2D游戏。\n",
      "\n",
      "7.  **教育（Education）**：\n",
      "    *   由于其易学性，Python常被用作编程入门的首选语言。\n",
      "\n",
      "### 一个简单的Python例子：\n",
      "\n",
      "让我们来看一个经典的“Hello, World!”和简单的计算例子：\n",
      "\n",
      "```python\n",
      "# 这是一个注释，Python会忽略它\n",
      "\n",
      "# 打印“Hello, World!”到控制台\n",
      "print(\"Hello, World!\")\n",
      "\n",
      "# 定义两个变量\n",
      "num1 = 10\n",
      "num2 = 5\n",
      "\n",
      "# 进行加法运算并打印结果\n",
      "sum_result = num1 + num2\n",
      "print(\"10 + 5 =\", sum_result)\n",
      "\n",
      "# 进行乘法运算并打印结果\n",
      "product_result = num1 * num2\n",
      "print(\"10 * 5 =\", product_result)\n",
      "```\n",
      "\n",
      "**运行结果：**\n",
      "\n",
      "```\n",
      "Hello, World!\n",
      "10 + 5 = 15\n",
      "10 * 5 = 50\n",
      "```\n",
      "\n",
      "可以看到，Python的代码非常直观，就像在写英语句子一样。\n",
      "\n",
      "### 如何开始学习Python：\n",
      "\n",
      "1.  **安装Python**：从Python官方网站（[https://www.python.org/](https://www.python.org/)）下载并安装最新版本。\n",
      "2.  **选择一个代码编辑器或集成开发环境（IDE）**：\n",
      "    *   **VS Code (Visual Studio Code)**：轻量、功能强大、插件丰富，适合各种开发。\n",
      "    *   **PyCharm**：专门为Python设计，功能全面，但可能对初学者来说有些复杂。\n",
      "    *   **Jupyter Notebook/JupyterLab**：特别适合数据科学和交互式编程。\n",
      "3.  **学习基础语法**：掌握变量、数据类型、运算符、条件语句、循环、函数、列表、字典等基本概念。\n",
      "4.  **多加练习**：通过解决小问题、编写小程序来巩固所学知识。\n",
      "5.  **阅读文档和教程**：Python官方文档非常完善，网上也有大量的免费教程和课程。\n",
      "6.  **参与社区**：在遇到问题时，可以去Stack Overflow、GitHub等社区寻求帮助。\n",
      "\n",
      "总而言之，Python是一门功能强大、应用广泛、且非常适合学习的编程语言。无论你是想进入IT行业，还是想提高工作效率，甚至是仅仅出于兴趣，学习Python都会是一个非常明智的选择。\n",
      "\n",
      "你对Python的哪个方面最感兴趣呢？或者有什么具体的问题想问吗？\n",
      "使用provider: gpt_light\n",
      "\n",
      "--- 第2轮对话 ---\n",
      "Using gpt_light (attempt 1/3)...\n",
      "✅ gpt_light succeeded\n",
      "用户: 那它主要用在什么场景？\n",
      "助手: 好的，Python 的应用场景确实非常广泛，几乎涵盖了软件开发的各个领域。以下是一些它主要被使用的场景：\n",
      "\n",
      "1.  **数据科学、机器学习与人工智能 (Data Science, Machine Learning & AI)**\n",
      "    *   **场景描述**：这是 Python 最热门和最有影响力的应用领域之一。从数据清洗、数据分析、数据可视化到构建复杂的机器学习模型和深度学习网络。\n",
      "    *   **为什么选择 Python**：拥有极其强大的生态系统，如：\n",
      "        *   **NumPy** (数值计算)\n",
      "        *   **Pandas** (数据处理和分析)\n",
      "        *   **Matplotlib, Seaborn** (数据可视化)\n",
      "        *   **Scikit-learn** (机器学习算法)\n",
      "        *   **TensorFlow, PyTorch, Keras** (深度学习框架)\n",
      "    *   **具体应用**：预测分析、推荐系统、自然语言处理 (NLP)、计算机视觉、语音识别、智能推荐等。\n",
      "\n",
      "2.  **Web 开发 (Web Development)**\n",
      "    *   **场景描述**：用于构建网站的后端逻辑（服务器端）。\n",
      "    *   **为什么选择 Python**：拥有成熟且功能强大的 Web 框架：\n",
      "        *   **Django**：一个“全栈式”的框架，提供大量开箱即用的功能，适合快速开发复杂、数据库驱动的网站。\n",
      "        *   **Flask**：一个“微框架”，更轻量级，灵活性高，适合构建小型应用或 API。\n",
      "    *   **具体应用**：内容管理系统、社交媒体网站、电商平台、RESTful API 服务等。\n",
      "\n",
      "3.  **自动化脚本与系统运维 (Automation & System Administration)**\n",
      "    *   **场景描述**：用于编写各种自动化脚本，提高工作效率，管理系统。\n",
      "    *   **为什么选择 Python**：其简洁的语法和丰富的系统交互库（如 `os`, `sys`, `subprocess`, `shutil`）使其成为理想的脚本语言。\n",
      "    *   **具体应用**：\n",
      "        *   **网络爬虫 (Web Scraping)**：使用 `Requests`, `BeautifulSoup`, `Scrapy` 等库从网页抓取数据。\n",
      "        *   **文件操作**：批量重命名文件、整理文件夹、处理 CSV/Excel 文件。\n",
      "        *   **系统管理**：监控服务器状态、自动化部署、备份数据、管理用户账户。\n",
      "        *   **任务调度**：定时执行特定任务。\n",
      "\n",
      "4.  **科学计算与数值分析 (Scientific Computing & Numerical Analysis)**\n",
      "    *   **场景描述**：在数学、物理、化学、生物、工程等领域进行复杂的计算和模拟。\n",
      "    *   **为什么选择 Python**：除了 NumPy，还有：\n",
      "        *   **SciPy**：提供科学和工程领域常用的算法和工具（如积分、优化、信号处理）。\n",
      "        *   **SymPy**：用于符号计算（代数运算）。\n",
      "    *   **具体应用**：数据建模、仿真、统计分析、物理模拟。\n",
      "\n",
      "5.  **桌面应用开发 (Desktop Applications)**\n",
      "    *   **场景描述**：虽然不是 Python 最主流的应用，但它也可以用于开发带有图形用户界面 (GUI) 的桌面应用程序。\n",
      "    *   **为什么选择 Python**：\n",
      "        *   **PyQt / PySide**：基于 Qt 库，功能强大，可以开发出专业级的桌面应用。\n",
      "        *   **Tkinter**：Python 标准库自带的 GUI 库，适合开发简单的应用。\n",
      "        *   **Kivy**：用于开发跨平台应用，包括移动端。\n",
      "    *   **具体应用**：小型工具、内部管理系统、特定功能的客户端程序。\n",
      "\n",
      "6.  **游戏开发 (Game Development)**\n",
      "    *   **场景描述**：主要用于开发 2D 游戏或作为游戏的原型开发。\n",
      "    *   **为什么选择 Python**：\n",
      "        *   **Pygame**：一个流行的 2D 游戏开发库，易于上手。\n",
      "    *   **具体应用**：休闲游戏、教育游戏、游戏脚本。\n",
      "\n",
      "7.  **教育与教学 (Education)**\n",
      "    *   **场景描述**：由于其易学性，Python 经常被用作编程入门的首选语言。\n",
      "    *   **为什么选择 Python**：语法简洁、可读性强，能够让初学者快速理解编程概念。\n",
      "\n",
      "**总结来说，Python之所以能在这么多场景中被广泛应用，主要得益于以下几点：**\n",
      "\n",
      "*   **易学易用**：语法简洁，上手快。\n",
      "*   **丰富的库和框架**：每个领域都有成熟的工具支持。\n",
      "*   **跨平台性**：一次编写，多处运行。\n",
      "*   **强大的社区支持**：遇到问题容易找到解决方案和资源。\n",
      "*   **通用性**：作为一种通用编程语言，它能适应各种不同的任务需求。\n",
      "\n",
      "可以说，无论你有什么样的编程需求，Python 往往都能提供一个高效且优雅的解决方案。\n",
      "使用provider: gpt_light\n",
      "\n",
      "--- 第3轮对话 ---\n",
      "Using gpt_light (attempt 1/3)...\n",
      "✅ gpt_light succeeded\n",
      "用户: 刚才你提到的应用场景中，哪个最容易入门？\n",
      "助手: 在您提到的这些应用场景中，**自动化脚本与系统运维 (Automation & Scripting)** 是最容易入门的。\n",
      "\n",
      "原因如下：\n",
      "\n",
      "1.  **极低的门槛和依赖：**\n",
      "    *   **你只需要Python解释器本身。** 不需要安装复杂的框架（如Django、TensorFlow），不需要配置数据库，也不需要理解HTTP协议、神经网络等复杂概念。\n",
      "    *   你可以直接在命令行或一个简单的文本编辑器中编写代码并运行，立即看到结果。\n",
      "\n",
      "2.  **直接应用基础语法：**\n",
      "    *   自动化脚本的核心就是运用Python最基础的语法元素：变量、数据类型、条件语句（if/else）、循环（for/while）、函数等。\n",
      "    *   你不需要学习特定领域（如Web开发中的MVC模式，机器学习中的模型训练流程）的架构和模式。\n",
      "\n",
      "3.  **即时反馈，成就感强：**\n",
      "    *   编写一个简单的脚本，比如批量修改文件名，或者从一个文本文件中提取信息，运行后你就能立刻看到效果。这种即时反馈能大大增强学习的动力和成就感。\n",
      "    *   相比之下，Web开发需要启动服务器，在浏览器中查看；数据科学可能需要较长时间的数据处理和模型训练。\n",
      "\n",
      "4.  **解决实际问题：**\n",
      "    *   即使是非常简单的脚本，也能解决你日常生活中遇到的重复性任务，比如：\n",
      "        *   自动整理文件夹中的文件。\n",
      "        *   批量处理图片或文档。\n",
      "        *   从网页上抓取一些简单的数据（比如天气预报）。\n",
      "        *   定时发送邮件或消息。\n",
      "    *   这些任务往往是你能直观理解并且有实际需求的，能让你感受到编程的实用价值。\n",
      "\n",
      "**入门示例：**\n",
      "\n",
      "*   **“Hello, World!”**：最简单的输出。\n",
      "    ```python\n",
      "    print(\"Hello, World!\")\n",
      "    ```\n",
      "*   **简单的计算器**：\n",
      "    ```python\n",
      "    num1 = 10\n",
      "    num2 = 20\n",
      "    sum_result = num1 + num2\n",
      "    print(\"和是:\", sum_result)\n",
      "    ```\n",
      "*   **文件操作**（创建一个文件并写入内容）：\n",
      "    ```python\n",
      "    with open(\"my_first_file.txt\", \"w\") as f:\n",
      "        f.write(\"这是我用Python创建的第一个文件。\\n\")\n",
      "        f.write(\"Python真棒！\")\n",
      "    print(\"文件创建成功！\")\n",
      "    ```\n",
      "*   **一个简单的批量重命名脚本概念**（不涉及复杂逻辑，仅展示思路）：\n",
      "    ```python\n",
      "    import os\n",
      "\n",
      "    # 假设你有一个文件夹，里面有很多文件需要重命名\n",
      "    # 比如：pic_001.jpg, pic_002.jpg ...\n",
      "    # 假设你只想打印出它们的名字，然后假装重命名\n",
      "    \n",
      "    folder_path = \".\" # 当前文件夹\n",
      "    \n",
      "    for filename in os.listdir(folder_path):\n",
      "        if filename.startswith(\"old_\") and filename.endswith(\".txt\"):\n",
      "            new_filename = filename.replace(\"old_\", \"new_\")\n",
      "            print(f\"将 '{filename}' 重命名为 '{new_filename}' (此处仅为演示，实际未执行重命名)\")\n",
      "            # 实际重命名代码：os.rename(os.path.join(folder_path, filename), os.path.join(folder_path, new_filename))\n",
      "    ```\n",
      "\n",
      "从自动化脚本开始学习，你可以扎实地掌握Python的基础语法和编程思维，为将来深入学习Web开发、数据科学等更复杂的领域打下坚实的基础。\n",
      "使用provider: gpt_light\n",
      "\n",
      "=== 完整对话历史 ===\n",
      "1. 用户: 你好！我想了解一下Python编程语言。\n",
      "2. 助手: 你好！很高兴为你介绍Python编程语言。\n",
      "\n",
      "Python是一种**高级（High-level）**...\n",
      "3. 用户: 那它主要用在什么场景？\n",
      "4. 助手: 好的，Python 的应用场景确实非常广泛，几乎涵盖了软件开发的各个领域。以下是一些它主要被使用的场...\n",
      "5. 用户: 刚才你提到的应用场景中，哪个最容易入门？\n",
      "6. 助手: 在您提到的这些应用场景中，**自动化脚本与系统运维 (Automation & Scripting)...\n",
      "\n",
      "✅ 多轮对话测试成功！共进行了 3 轮对话\n"
>>>>>>> 7f5a145781e4be1df374c9d1fdb11b39af106008
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# 简单的文本生成测试\n",
    "print(\"=== 基本文本生成测试 ===\")\n",
    "\n",
    "test_prompt = \"简单回答：1+1等于几？\"\n",
    "\n",
    "try:\n",
    "    response = llm.generate(test_prompt, verbose=True)\n",
    "    print(f\"\\n✅ 测试成功！\")\n",
    "    print(f\"回复: {response}\")\n",
    "    print(f\"使用的provider: {llm.current_provider}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 测试失败: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 中文问答测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 中文问答测试 ===\n",
      "✅ 中文回复成功\n",
      "问题: 用中文简单介绍一下Python编程语言的特点（50字以内）\n",
      "回复: Python语法简洁易读，支持面向对象和函数式编程，拥有丰富的标准库和第三方模块，跨平台且扩展性强，广泛应用于数据分析、AI和Web开发。\n",
      "使用provider: gpt_free\n"
     ]
    }
   ],
   "source": [
    "# 中文问答测试\n",
    "print(\"=== 中文问答测试 ===\")\n",
    "\n",
    "chinese_prompt = \"用中文简单介绍一下Python编程语言的特点（50字以内）\"\n",
    "\n",
    "try:\n",
    "    response = llm.generate(chinese_prompt)\n",
    "    print(f\"✅ 中文回复成功\")\n",
    "    print(f\"问题: {chinese_prompt}\")\n",
    "    print(f\"回复: {response}\")\n",
    "    print(f\"使用provider: {llm.current_provider}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 中文回复失败: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fallback机制测试\n",
    "\n",
    "测试当第一个provider不可用时，是否能自动切换到下一个provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fallback机制测试 ===\n",
      "当前fallback顺序: ['gpt_free', 'ollama']\n",
      "第1次调用成功，使用provider: gpt_free\n",
      "第2次调用成功，使用provider: gpt_free\n",
      "第3次调用成功，使用provider: gpt_free\n"
     ]
    }
   ],
   "source": [
    "# 测试fallback机制\n",
    "print(\"=== Fallback机制测试 ===\")\n",
    "\n",
    "# 显示当前fallback顺序\n",
    "print(f\"当前fallback顺序: {llm.config.get('active_fallback_list', [])}\")\n",
    "\n",
    "# 进行几次调用，观察是否稳定使用相同provider\n",
    "for i in range(3):\n",
    "    try:\n",
    "        response = llm.generate(f\"回答数字：{i+1}\")\n",
    "        print(f\"第{i+1}次调用成功，使用provider: {llm.current_provider}\")\n",
    "    except Exception as e:\n",
    "        print(f\"第{i+1}次调用失败: {e}\")"
=======
    "def multi_turn_chat_test():\n",
    "    \"\"\"多轮对话测试 - 测试新的chat()方法\"\"\"\n",
    "    \n",
    "    # 重置实例确保干净状态\n",
    "    from llm_api.universal_llm import UniversalLLM\n",
    "    UniversalLLM.reset_instance()\n",
    "    \n",
    "    llm = create_llm(\"base\")  # 使用base配置\n",
    "    \n",
    "    print(\"=== 多轮对话测试 ===\")\n",
    "    print(f\"使用的fallback列表: {llm.config.get('active_fallback_list', [])}\")\n",
    "    \n",
    "    # 模拟一个完整的多轮对话\n",
    "    conversation_history = []\n",
    "    \n",
    "    # 第一轮对话\n",
    "    print(\"\\n--- 第1轮对话 ---\")\n",
    "    user_msg_1 = \"你好！我想了解一下Python编程语言。\"\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_msg_1})\n",
    "    \n",
    "    try:\n",
    "        response_1 = llm.chat(conversation_history.copy(), verbose=True)\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": response_1})\n",
    "        \n",
    "        print(f\"用户: {user_msg_1}\")\n",
    "        print(f\"助手: {response_1}\")\n",
    "        print(f\"使用provider: {llm.current_provider}\")\n",
    "    except Exception as e:\n",
    "        print(f\"第1轮对话失败: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # 第二轮对话 - 基于上下文\n",
    "    print(\"\\n--- 第2轮对话 ---\")\n",
    "    user_msg_2 = \"那它主要用在什么场景？\"\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_msg_2})\n",
    "    \n",
    "    try:\n",
    "        response_2 = llm.chat(conversation_history.copy(), verbose=True)\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": response_2})\n",
    "        \n",
    "        print(f\"用户: {user_msg_2}\")\n",
    "        print(f\"助手: {response_2}\")\n",
    "        print(f\"使用provider: {llm.current_provider}\")\n",
    "    except Exception as e:\n",
    "        print(f\"第2轮对话失败: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # 第三轮对话 - 进一步深入\n",
    "    print(\"\\n--- 第3轮对话 ---\")\n",
    "    user_msg_3 = \"刚才你提到的应用场景中，哪个最容易入门？\"\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_msg_3})\n",
    "    \n",
    "    try:\n",
    "        response_3 = llm.chat(conversation_history.copy(), verbose=True)\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": response_3})\n",
    "        \n",
    "        print(f\"用户: {user_msg_3}\")\n",
    "        print(f\"助手: {response_3}\")\n",
    "        print(f\"使用provider: {llm.current_provider}\")\n",
    "    except Exception as e:\n",
    "        print(f\"第3轮对话失败: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # 显示完整对话历史\n",
    "    print(\"\\n=== 完整对话历史 ===\")\n",
    "    for i, msg in enumerate(conversation_history):\n",
    "        role_name = \"用户\" if msg[\"role\"] == \"user\" else \"助手\"\n",
    "        print(f\"{i+1}. {role_name}: {msg['content'][:50]}{'...' if len(msg['content']) > 50 else ''}\")\n",
    "    \n",
    "    print(f\"\\n✅ 多轮对话测试成功！共进行了 {len([msg for msg in conversation_history if msg['role'] == 'user'])} 轮对话\")\n",
    "    return True\n",
    "\n",
    "# 运行多轮对话测试\n",
    "multi_turn_success = multi_turn_chat_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 多轮对话测试\n",
    "\n",
    "测试新添加的多轮对话功能 - 使用 `chat()` 方法而非 `generate()`"
>>>>>>> 7f5a145781e4be1df374c9d1fdb11b39af106008
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snail-trader",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
